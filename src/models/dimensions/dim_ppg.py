#!/usr/bin/env python3
"""
Populador da Dimens√£o PPG (Programas de P√≥s-Gradua√ß√£o)
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime

# Adicionar path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from src.core.core import get_db_manager, get_capes_api, Config, log_execution
import logging

logger = logging.getLogger(__name__)

@log_execution
def extrair_dados_ppg_api():
    """
    Extrai dados dos PPGs da API CAPES.
    """
    logger.info("üèõÔ∏è Extraindo dados dos PPGs da API CAPES...")
    
    try:
        api = get_capes_api()
        config = Config()
        
        # Buscar dados de PPG
        resource_id = config.RESOURCE_IDS.get('ppg', '21be9dd6-d4fa-470e-a5b9-b59c20879f10')
        
        df_raw = api.fetch_all_data(resource_id)
        
        if df_raw.empty:
            logger.error("‚ùå Nenhum dado de PPG encontrado na API")
            return pd.DataFrame()
        
        logger.info(f"‚úÖ Dados dos PPGs extra√≠dos: {len(df_raw)} registros")
        return df_raw
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao extrair dados da API: {e}")
        return pd.DataFrame()

@log_execution
def processar_dados_ppg(df_raw):
    """
    Processa e limpa os dados dos PPGs.
    """
    logger.info("üîÑ Processando dados dos PPGs...")
    
    try:
        if df_raw.empty:
            logger.error("‚ùå DataFrame vazio para processamento")
            return pd.DataFrame()
        
        # Mapear colunas baseado nos dados reais da API
        colunas_mapeamento = {
            'codigo_programa': 'CD_PROGRAMA_IES',
            'nome_programa': 'NM_PROGRAMA_IES', 
            'nivel_programa': 'CD_NIVEL_PROGRAMA',
            'ies_vinculada': 'NM_ENTIDADE_ENSINO',
            'codigo_ies': 'CD_ENTIDADE_ENSINO',
            'sigla_ies': 'SG_ENTIDADE_ENSINO',
            'uf': 'SG_UF_IES',
            'regiao': 'NM_REGIAO',
            'area_conhecimento': 'NM_AREA_CONHECIMENTO',
            'area_avaliacao': 'NM_AREA_AVALIACAO',
            'modalidade': 'NM_MODALIDADE_PROGRAMA',
            'nota_capes': 'NR_NOTA_PROGRAMA',
            'situacao': 'DS_SITUACAO_PROGRAMA',
            'ano_base': 'AN_BASE'
        }
        
        # Verificar quais colunas existem no DataFrame
        colunas_existentes = {}
        for col_nova, col_original in colunas_mapeamento.items():
            colunas_disponiveis = [c for c in df_raw.columns if col_original.upper() in c.upper()]
            if colunas_disponiveis:
                colunas_existentes[col_nova] = colunas_disponiveis[0]
            else:
                logger.warning(f"‚ö†Ô∏è Coluna {col_original} n√£o encontrada")
        
        # Criar DataFrame processado
        df_processado = pd.DataFrame()
        
        for col_nova, col_original in colunas_existentes.items():
            df_processado[col_nova] = df_raw[col_original]
        
        # Tratar valores nulos e padronizar
        df_processado = df_processado.fillna('Desconhecido')
        
        # Normalizar strings
        string_cols = ['nome_programa', 'ies_vinculada', 'sigla_ies', 'uf', 'regiao', 
                      'area_conhecimento', 'area_avaliacao', 'modalidade', 'situacao']
        
        for col in string_cols:
            if col in df_processado.columns:
                df_processado[col] = df_processado[col].astype(str).str.strip().str.upper()
        
        # Padronizar regi√£o
        if 'regiao' in df_processado.columns:
            regiao_map = {
                'NORTE': 'Norte',
                'NORDESTE': 'Nordeste', 
                'CENTRO-OESTE': 'Centro-Oeste',
                'SUDESTE': 'Sudeste',
                'SUL': 'Sul'
            }
            df_processado['regiao'] = df_processado['regiao'].map(regiao_map).fillna('Desconhecido')
        
        # Tratar ano base
        if 'ano_base' in df_processado.columns:
            df_processado['ano_base'] = pd.to_numeric(df_processado['ano_base'], errors='coerce').fillna(2024).astype(int)
        else:
            df_processado['ano_base'] = 2024
        
        # Tratar nota CAPES
        if 'nota_capes' in df_processado.columns:
            df_processado['nota_capes'] = pd.to_numeric(df_processado['nota_capes'], errors='coerce').fillna(0)
        else:
            df_processado['nota_capes'] = 0
        
        # Remover duplicatas
        colunas_duplicata = ['codigo_programa', 'nome_programa', 'ies_vinculada']
        colunas_existentes_dup = [col for col in colunas_duplicata if col in df_processado.columns]
        
        if colunas_existentes_dup:
            registros_antes = len(df_processado)
            df_processado = df_processado.drop_duplicates(subset=colunas_existentes_dup)
            registros_depois = len(df_processado)
            logger.info(f"üìä Duplicatas removidas: {registros_antes - registros_depois}")
        
        logger.info(f"‚úÖ Dados dos PPGs processados: {len(df_processado)} registros")
        return df_processado
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao processar dados: {e}")
        return pd.DataFrame()

@log_execution
def criar_dimensao_ppg(df_processado):
    """
    Cria a dimens√£o PPG com SK e estrutura adequada.
    """
    logger.info("üèóÔ∏è Criando dimens√£o PPG...")
    
    try:
        if df_processado.empty:
            logger.warning("‚ö†Ô∏è DataFrame vazio - criando apenas registro SK=0")
            df_ppg = pd.DataFrame([{
                'ppg_sk': 0,
                'codigo_programa': 'DESCONHECIDO',
                'nome_programa': 'Desconhecido',
                'nivel_programa': 'DESCONHECIDO',
                'ies_vinculada': 'Desconhecido',
                'codigo_ies': 'DESCONHECIDO',
                'sigla_ies': 'DESCONHECIDO',
                'uf': 'DESCONHECIDO',
                'regiao': 'Desconhecido',
                'area_conhecimento': 'Desconhecido',
                'area_avaliacao': 'Desconhecido',
                'modalidade': 'Desconhecido',
                'nota_capes': 0.0,
                'situacao': 'DESCONHECIDO',
                'ano_base': 2024
            }])
        else:
            # Criar registro SK=0 (desconhecido)
            registro_desconhecido = {
                'ppg_sk': 0,
                'codigo_programa': 'DESCONHECIDO',
                'nome_programa': 'Desconhecido',
                'nivel_programa': 'DESCONHECIDO',
                'ies_vinculada': 'Desconhecido',
                'codigo_ies': 'DESCONHECIDO',
                'sigla_ies': 'DESCONHECIDO',
                'uf': 'DESCONHECIDO',
                'regiao': 'Desconhecido',
                'area_conhecimento': 'Desconhecido',
                'area_avaliacao': 'Desconhecido',
                'modalidade': 'Desconhecido',
                'nota_capes': 0.0,
                'situacao': 'DESCONHECIDO',
                'ano_base': 2024
            }
            
            # Criar dimens√£o com dados processados
            df_ppg = df_processado.copy()
            
            # Adicionar surrogate key sequencial
            df_ppg['ppg_sk'] = range(1, len(df_ppg) + 1)
            
            # Garantir que todas as colunas existam
            colunas_obrigatorias = [
                'codigo_programa', 'nome_programa', 'nivel_programa', 'ies_vinculada',
                'codigo_ies', 'sigla_ies', 'uf', 'regiao', 'area_conhecimento',
                'area_avaliacao', 'modalidade', 'nota_capes', 'situacao', 'ano_base'
            ]
            
            for col in colunas_obrigatorias:
                if col not in df_ppg.columns:
                    df_ppg[col] = 'Desconhecido' if col != 'nota_capes' and col != 'ano_base' else (0.0 if col == 'nota_capes' else 2024)
            
            # Adicionar registro SK=0 no in√≠cio
            df_ppg = pd.concat([pd.DataFrame([registro_desconhecido]), df_ppg], ignore_index=True)
        
        # Reordenar colunas
        colunas_finais = [
            'ppg_sk', 'codigo_programa', 'nome_programa', 'nivel_programa',
            'ies_vinculada', 'codigo_ies', 'sigla_ies', 'uf', 'regiao',
            'area_conhecimento', 'area_avaliacao', 'modalidade', 
            'nota_capes', 'situacao', 'ano_base'
        ]
        
        df_ppg = df_ppg[colunas_finais]
        
        logger.info(f"‚úÖ Dimens√£o PPG criada com {len(df_ppg)} registros")
        return df_ppg
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar dimens√£o: {e}")
        return pd.DataFrame()

@log_execution
def salvar_dimensao_ppg(df_ppg):
    """
    Salva a dimens√£o PPG no banco de dados.
    """
    try:
        if df_ppg.empty:
            logger.error("‚ùå DataFrame vazio - n√£o h√° dados para salvar")
            return False
            
        db = get_db_manager()
        success = db.save_dataframe(df_ppg, 'dim_ppg', if_exists='replace')
        
        if success:
            logger.info(f"‚úÖ Dimens√£o PPG salva no PostgreSQL com {len(df_ppg)} registros")
            return True
        else:
            logger.error("‚ùå Falha ao salvar dimens√£o PPG")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao salvar dimens√£o: {e}")
        return False

@log_execution
def gerar_estatisticas_ppg(df_ppg):
    """
    Gera estat√≠sticas da dimens√£o PPG.
    """
    if df_ppg.empty:
        logger.info("‚ùå N√£o h√° dados para gerar estat√≠sticas")
        return
        
    logger.info("\nüìä Estat√≠sticas da dimens√£o PPG:")
    logger.info(f"Total de PPGs: {len(df_ppg)}")
    
    # Estat√≠sticas por regi√£o
    if 'regiao' in df_ppg.columns:
        logger.info("\nPPGs por regi√£o:")
        regiao_stats = df_ppg['regiao'].value_counts()
        for regiao, count in regiao_stats.items():
            logger.info(f"  {regiao}: {count} PPGs")
    
    # Estat√≠sticas por UF
    if 'uf' in df_ppg.columns:
        logger.info(f"\nUFs √∫nicas: {df_ppg['uf'].nunique()}")
    
    # Estat√≠sticas por modalidade
    if 'modalidade' in df_ppg.columns:
        logger.info("\nPPGs por modalidade:")
        modalidade_stats = df_ppg['modalidade'].value_counts()
        for modalidade, count in modalidade_stats.items():
            logger.info(f"  {modalidade}: {count} PPGs")
    
    # Notas CAPES
    if 'nota_capes' in df_ppg.columns:
        notas_validas = df_ppg[df_ppg['nota_capes'] > 0]
        if not notas_validas.empty:
            logger.info(f"\nNota CAPES m√©dia: {notas_validas['nota_capes'].mean():.1f}")
            logger.info(f"Nota CAPES mediana: {notas_validas['nota_capes'].median():.1f}")

def main():
    """
    Fun√ß√£o principal para execu√ß√£o do script.
    """
    try:
        logger.info("üöÄ Iniciando processo de cria√ß√£o da dimens√£o PPG")
        logger.info("üèõÔ∏è Fonte de dados: API CAPES")
        
        # 1. Extrair dados da API
        df_raw = extrair_dados_ppg_api()
        
        # 2. Processar dados
        df_processado = processar_dados_ppg(df_raw)
        
        # 3. Criar dimens√£o
        df_ppg = criar_dimensao_ppg(df_processado)
        
        if df_ppg.empty:
            logger.error("‚ùå Falha ao criar dimens√£o PPG")
            return False
        
        # 4. Salvar no banco
        if not salvar_dimensao_ppg(df_ppg):
            return False
        
        # 5. Gerar estat√≠sticas
        gerar_estatisticas_ppg(df_ppg)
        
        logger.info("‚úÖ Processo conclu√≠do! Dimens√£o PPG criada com sucesso.")
        logger.info("üí° A dimens√£o inclui informa√ß√µes sobre programas de p√≥s-gradua√ß√£o.")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na execu√ß√£o principal: {e}")
        return False

if __name__ == "__main__":
    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    success = main()
    sys.exit(0 if success else 1)
