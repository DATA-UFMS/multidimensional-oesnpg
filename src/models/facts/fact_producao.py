#!/usr/bin/env python3
"""
fact_producao.py

M√≥dulo para cria√ß√£o e gerenciamento da tabela fato de produ√ß√£o intelectual no Data Warehouse.

Descri√ß√£o:
    Este m√≥dulo implementa o processo de ETL (Extract, Transform, Load) para a tabela fato
    de produ√ß√£o intelectual da p√≥s-gradua√ß√£o brasileira. Registra a produ√ß√£o cient√≠fica
    (artigos, livros, trabalhos em eventos, etc.) e suas autorias.
    
    A tabela fato cont√©m:
    - Chaves estrangeiras para dimens√µes (docente, discente, titulado, posdoc, tempo, localidade)
    - M√©tricas de produ√ß√£o
    - Fatos sobre a autoria (tipo de autor, ordem, categoria)
    
Fontes de Dados:
    - Base Principal: add_producao_autor_2023.parquet (MinIO S3)
    - Fallback: Arquivo local em data/raw_producao/add_producao_autor_2023.parquet
    - Dimens√µes: dim_docente, dim_discente, dim_titulado, dim_posdoc, dim_tempo, dim_localidade

Estrutura da Tabela Fato:
    - producao_id: ID √∫nico da produ√ß√£o intelectual
    - tempo_sk: Chave estrangeira para dim_tempo (ano base)
    - docente_sk: Chave estrangeira para dim_docente (autor docente)
    - discente_sk: Chave estrangeira para dim_discente (autor discente)
    - titulado_sk: Chave estrangeira para dim_titulado (autor titulado/egresso)
    - posdoc_sk: Chave estrangeira para dim_posdoc (autor p√≥s-doc)
    - localidade_sk: Chave estrangeira para dim_localidade (IES do programa)
    - tipo_producao: Tipo da produ√ß√£o (1=Bibliogr√°fica, 2=T√©cnica, 3=Art√≠stica)
    - subtipo_producao: Subtipo espec√≠fico da produ√ß√£o
    - tipo_autor: Categoria do autor (DOCENTE, DISCENTE, P√ìS-DOC, EGRESSO, PARTICIPANTE EXTERNO)
    - ordem_autor: Ordem do autor na produ√ß√£o
    - qtd_producao: Sempre 1 (para agrega√ß√£o)
    
Processo ETL:
    1. Carregamento: L√™ dados do MinIO ou arquivo local
    2. Transforma√ß√£o: 
       - Mapeia IDs de pessoas para surrogate keys das dimens√µes
       - Trata valores nulos com SK=0 (unknown)
       - Calcula m√©tricas agregadas
    3. Carga: Insere em chunks no PostgreSQL

Regras de Neg√≥cio:
    - Cada registro representa uma autoria de produ√ß√£o
    - Uma produ√ß√£o pode ter m√∫ltiplos autores
    - SKs ausentes s√£o preenchidos com 0 (unknown)
    - Produ√ß√£o sem autor conhecido √© registrada com todos SKs=0
    - Agrega√ß√µes s√£o feitas por soma de qtd_producao
    
Autor: Sistema DW OESNPG
Data: 2025-10-14
"""

import sys
import os
import pandas as pd
import logging
from datetime import datetime

# Adicionar o diret√≥rio raiz ao path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
sys.path.insert(0, project_root)

from dotenv import load_dotenv
from src.core.core import get_db_manager

# Carregar vari√°veis de ambiente
load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

def get_logger():
    return logger


def carregar_dados_producao():
    """
    Carrega dados de produ√ß√£o intelectual do arquivo Parquet (MinIO ou local).
    
    Returns:
        DataFrame com dados de produ√ß√£o e autoria
    """
    try:
        logger.info("üìö Carregando dados de produ√ß√£o intelectual...")
        
        # Tentar carregar dados locais primeiro
        local_path = os.path.join(project_root, 'data', 'raw_producao', 'add_producao_autor_2023.parquet')
        
        if os.path.exists(local_path):
            logger.info(f"Carregando dados locais de {local_path}")
            df = pd.read_parquet(local_path)
            logger.info(f"‚úÖ Dados locais carregados: {len(df):,} registros")
            return df
        
        # Se n√£o encontrar local, tentar MinIO
        logger.info("Arquivo local n√£o encontrado. Tentando MinIO...")
        
        # Obter credenciais das vari√°veis de ambiente
        endpoint = os.getenv("MINIO_ENDPOINT", "http://localhost:9000")
        bucket = os.getenv("MINIO_BUCKET", "observatorio-servicos-bronze")
        access_key = os.getenv("MINIO_ACCESS_KEY")
        secret_key = os.getenv("MINIO_SECRET_KEY")
        
        if not access_key or not secret_key:
            raise ValueError("‚ùå Credenciais do MinIO n√£o configuradas (MINIO_ACCESS_KEY, MINIO_SECRET_KEY)")
        
        storage_options = {
            'key': access_key,
            'secret': secret_key,
            'client_kwargs': {'endpoint_url': endpoint}
        }
        
        path = f"s3://{bucket}/add_capes/add_producao_autor_2023.parquet"
        logger.info(f"Tentando carregar de: {path}")
        
        df = pd.read_parquet(path, storage_options=storage_options)
        logger.info(f"‚úÖ Dados carregados do MinIO: {len(df):,} registros")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Falha ao carregar dados: {e}")
        raise


def carregar_dimensoes(db):
    """
    Carrega os mapeamentos de IDs das dimens√µes para surrogate keys.
    
    Args:
        db: Gerenciador de banco de dados
        
    Returns:
        dict: Dicion√°rios de mapeamento para cada dimens√£o
    """
    logger.info("üìä Carregando mapeamentos das dimens√µes...")
    
    mapeamentos = {}
    
    # dim_docente: id_pessoa -> docente_sk
    logger.info("  Carregando dim_docente...")
    docentes = db.execute_query("SELECT CAST(id_pessoa AS VARCHAR) as id_pessoa, docente_sk FROM dim_docente WHERE docente_sk > 0")
    mapeamentos['docente'] = dict(zip(docentes['id_pessoa'].astype(str), docentes['docente_sk']))
    logger.info(f"    ‚úÖ {len(mapeamentos['docente']):,} docentes mapeados")
    
    # dim_discente: id_pessoa -> discente_sk
    logger.info("  Carregando dim_discente...")
    discentes = db.execute_query("SELECT CAST(id_pessoa AS VARCHAR) as id_pessoa, discente_sk FROM dim_discente WHERE discente_sk > 0")
    mapeamentos['discente'] = dict(zip(discentes['id_pessoa'].astype(str), discentes['discente_sk']))
    logger.info(f"    ‚úÖ {len(mapeamentos['discente']):,} discentes mapeados")
    
    # dim_titulado: id_pessoa -> titulado_sk
    logger.info("  Carregando dim_titulado...")
    titulados = db.execute_query("SELECT CAST(id_pessoa AS VARCHAR) as id_pessoa, titulado_sk FROM dim_titulado WHERE titulado_sk > 0")
    mapeamentos['titulado'] = dict(zip(titulados['id_pessoa'].astype(str), titulados['titulado_sk']))
    logger.info(f"    ‚úÖ {len(mapeamentos['titulado']):,} titulados mapeados")
    
    # dim_posdoc: id_pessoa -> posdoc_sk
    logger.info("  Carregando dim_posdoc...")
    posdocs = db.execute_query("SELECT CAST(id_pessoa AS VARCHAR) as id_pessoa, posdoc_sk FROM dim_posdoc WHERE posdoc_sk > 0")
    mapeamentos['posdoc'] = dict(zip(posdocs['id_pessoa'].astype(str), posdocs['posdoc_sk']))
    logger.info(f"    ‚úÖ {len(mapeamentos['posdoc']):,} p√≥s-docs mapeados")
    
    # dim_tempo: ano -> tempo_sk
    logger.info("  Carregando dim_tempo...")
    tempos = db.execute_query("SELECT ano, tempo_sk FROM dim_tempo WHERE tempo_sk > 0")
    mapeamentos['tempo'] = dict(zip(tempos['ano'].astype(int), tempos['tempo_sk']))
    logger.info(f"    ‚úÖ {len(mapeamentos['tempo']):,} anos mapeados")
    
    logger.info("‚úÖ Todos os mapeamentos carregados com sucesso")
    return mapeamentos


def transformar_dados_producao(df, mapeamentos):
    """
    Transforma os dados de produ√ß√£o para a tabela fato.
    
    Args:
        df: DataFrame com dados brutos de produ√ß√£o
        mapeamentos: Dicion√°rios de mapeamento das dimens√µes
        
    Returns:
        DataFrame transformado para inser√ß√£o na tabela fato
    """
    logger.info("üîÑ Transformando dados para tabela fato de produ√ß√£o...")
    logger.info(f"Total de registros a transformar: {len(df):,}")
    
    # Selecionar colunas relevantes
    df_fato = df[[
        'ID_ADD_PRODUCAO_INTELECTUAL',
        'AN_BASE_PRODUCAO',
        'ID_TIPO_PRODUCAO',
        'ID_SUBTIPO_PRODUCAO',
        'TP_AUTOR',
        'NR_ORDEM',
        'ID_PESSOA_DOCENTE',
        'ID_PESSOA_DISCENTE',
        'ID_PESSOA_POS_DOC',
        'ID_PESSOA_EGRESSO',
        'CD_PROGRAMA',
        'SG_IES'
    ]].copy()
    
    # Renomear colunas
    df_fato = df_fato.rename(columns={
        'ID_ADD_PRODUCAO_INTELECTUAL': 'producao_id',
        'AN_BASE_PRODUCAO': 'ano_base',
        'ID_TIPO_PRODUCAO': 'tipo_producao',
        'ID_SUBTIPO_PRODUCAO': 'subtipo_producao',
        'TP_AUTOR': 'tipo_autor',
        'NR_ORDEM': 'ordem_autor'
    })
    
    # Mapear IDs para surrogate keys
    logger.info("Mapeando IDs para surrogate keys...")
    
    # Mapear tempo_sk
    df_fato['tempo_sk'] = df_fato['ano_base'].fillna(0).astype(int).astype(str).map(mapeamentos['tempo']).fillna(0).astype(int)
    
    # Mapear docente_sk (converter float -> int -> string para evitar '177173.0')
    df_fato['docente_sk'] = df_fato['ID_PESSOA_DOCENTE'].fillna(0).astype(int).astype(str).map(mapeamentos['docente']).fillna(0).astype(int)
    
    # Mapear discente_sk (converter float -> int -> string para evitar '177173.0')
    df_fato['discente_sk'] = df_fato['ID_PESSOA_DISCENTE'].fillna(0).astype(int).astype(str).map(mapeamentos['discente']).fillna(0).astype(int)
    
    # Mapear posdoc_sk (converter float -> int -> string para evitar '177173.0')
    df_fato['posdoc_sk'] = df_fato['ID_PESSOA_POS_DOC'].fillna(0).astype(int).astype(str).map(mapeamentos['posdoc']).fillna(0).astype(int)
    
    # Mapear titulado_sk (egressos) (converter float -> int -> string para evitar '177173.0')
    df_fato['titulado_sk'] = df_fato['ID_PESSOA_EGRESSO'].fillna(0).astype(int).astype(str).map(mapeamentos['titulado']).fillna(0).astype(int)
    
    # Por enquanto, localidade_sk = 0 (n√£o temos dim_ies ainda)
    df_fato['localidade_sk'] = 0
    
    # Adicionar m√©trica de contagem
    df_fato['qtd_producao'] = 1
    
    # Tratar valores nulos no tipo_autor
    df_fato['tipo_autor'] = df_fato['tipo_autor'].fillna('N√ÉO INFORMADO')
    df_fato['tipo_autor'] = df_fato['tipo_autor'].replace('-', 'PARTICIPANTE EXTERNO')
    
    # Selecionar apenas colunas finais
    colunas_finais = [
        'producao_id',
        'tempo_sk',
        'docente_sk',
        'discente_sk',
        'titulado_sk',
        'posdoc_sk',
        'localidade_sk',
        'tipo_producao',
        'subtipo_producao',
        'tipo_autor',
        'ordem_autor',
        'qtd_producao'
    ]
    
    df_fato = df_fato[colunas_finais]
    
    # Estat√≠sticas de mapeamento
    logger.info("\nüìä Estat√≠sticas de mapeamento:")
    logger.info(f"  Autores docentes mapeados: {(df_fato['docente_sk'] > 0).sum():,}")
    logger.info(f"  Autores discentes mapeados: {(df_fato['discente_sk'] > 0).sum():,}")
    logger.info(f"  Autores titulados mapeados: {(df_fato['titulado_sk'] > 0).sum():,}")
    logger.info(f"  Autores p√≥s-docs mapeados: {(df_fato['posdoc_sk'] > 0).sum():,}")
    logger.info(f"  Produ√ß√µes com ao menos um autor mapeado: {((df_fato['docente_sk'] > 0) | (df_fato['discente_sk'] > 0) | (df_fato['titulado_sk'] > 0) | (df_fato['posdoc_sk'] > 0)).sum():,}")
    
    logger.info(f"‚úÖ Tabela fato transformada: {len(df_fato):,} registros")
    return df_fato


def criar_tabela(db):
    """
    Cria a tabela fact_producao no banco de dados.
    
    Args:
        db: Gerenciador de banco de dados
    """
    logger.info("üóÑÔ∏è Criando tabela fact_producao...")
    
    # Dropar tabela se existir
    drop_sql = "DROP TABLE IF EXISTS fact_producao CASCADE;"
    db.execute_sql(drop_sql)
    logger.info("üóëÔ∏è Tabela fact_producao removida se existia")
    
    # Criar tabela
    create_sql = """
    CREATE TABLE fact_producao (
        producao_id BIGINT NOT NULL,
        tempo_sk INTEGER NOT NULL DEFAULT 0,
        docente_sk INTEGER NOT NULL DEFAULT 0,
        discente_sk INTEGER NOT NULL DEFAULT 0,
        titulado_sk INTEGER NOT NULL DEFAULT 0,
        posdoc_sk INTEGER NOT NULL DEFAULT 0,
        localidade_sk INTEGER NOT NULL DEFAULT 0,
        tipo_producao INTEGER NOT NULL,
        subtipo_producao INTEGER NOT NULL,
        tipo_autor VARCHAR(50),
        ordem_autor INTEGER,
        qtd_producao INTEGER NOT NULL DEFAULT 1,
        CONSTRAINT fk_tempo FOREIGN KEY (tempo_sk) REFERENCES dim_tempo(tempo_sk),
        CONSTRAINT fk_docente FOREIGN KEY (docente_sk) REFERENCES dim_docente(docente_sk),
        CONSTRAINT fk_discente FOREIGN KEY (discente_sk) REFERENCES dim_discente(discente_sk),
        CONSTRAINT fk_titulado FOREIGN KEY (titulado_sk) REFERENCES dim_titulado(titulado_sk),
        CONSTRAINT fk_posdoc FOREIGN KEY (posdoc_sk) REFERENCES dim_posdoc(posdoc_sk)
    );
    """
    
    db.execute_sql(create_sql)
    logger.info("‚úÖ Tabela fact_producao criada com sucesso")
    
    # Adicionar coment√°rios
    comment_sql = """
    COMMENT ON TABLE fact_producao IS 'Tabela fato de produ√ß√£o intelectual da p√≥s-gradua√ß√£o';
    COMMENT ON COLUMN fact_producao.producao_id IS 'ID √∫nico da produ√ß√£o intelectual';
    COMMENT ON COLUMN fact_producao.tempo_sk IS 'FK para dim_tempo (ano base da produ√ß√£o)';
    COMMENT ON COLUMN fact_producao.docente_sk IS 'FK para dim_docente (autor docente), 0 se n√£o aplic√°vel';
    COMMENT ON COLUMN fact_producao.discente_sk IS 'FK para dim_discente (autor discente), 0 se n√£o aplic√°vel';
    COMMENT ON COLUMN fact_producao.titulado_sk IS 'FK para dim_titulado (autor egresso), 0 se n√£o aplic√°vel';
    COMMENT ON COLUMN fact_producao.posdoc_sk IS 'FK para dim_posdoc (autor p√≥s-doc), 0 se n√£o aplic√°vel';
    COMMENT ON COLUMN fact_producao.localidade_sk IS 'FK para dim_localidade (IES do programa)';
    COMMENT ON COLUMN fact_producao.tipo_producao IS 'Tipo de produ√ß√£o (1=Bibliogr√°fica, 2=T√©cnica, 3=Art√≠stica)';
    COMMENT ON COLUMN fact_producao.subtipo_producao IS 'Subtipo espec√≠fico da produ√ß√£o';
    COMMENT ON COLUMN fact_producao.tipo_autor IS 'Categoria do autor (DOCENTE, DISCENTE, etc)';
    COMMENT ON COLUMN fact_producao.ordem_autor IS 'Ordem do autor na lista de autoria';
    COMMENT ON COLUMN fact_producao.qtd_producao IS 'Quantidade (sempre 1 para agrega√ß√£o)';
    """
    db.execute_sql(comment_sql)
    logger.info("‚úÖ Coment√°rios adicionados √† tabela")


def inserir_dados_producao(df, db, chunk_size=500):
    """
    Insere dados na tabela fact_producao em chunks.
    
    Args:
        df: DataFrame com dados transformados
        db: Gerenciador de banco de dados
        chunk_size: Tamanho dos chunks para inser√ß√£o
    """
    logger.info(f"üíæ Iniciando inser√ß√£o de {len(df):,} registros de produ√ß√£o...")
    
    total_chunks = (len(df) + chunk_size - 1) // chunk_size
    logger.info(f"üì¶ Dados ser√£o inseridos em {total_chunks:,} chunks de {chunk_size} registros")
    
    registros_inseridos = 0
    
    for i in range(0, len(df), chunk_size):
        chunk_num = (i // chunk_size) + 1
        chunk = df.iloc[i:i + chunk_size]
        
        logger.info(f"üì¶ Inserindo chunk {chunk_num}/{total_chunks} - Registros {i} a {min(i+chunk_size-1, len(df)-1)} ({len(chunk)} registros)")
        
        start_time = datetime.now()
        
        try:
            inserir_chunk_direto(chunk, db)
            registros_inseridos += len(chunk)
            
            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚úÖ Chunk {chunk_num} inserido com sucesso em {elapsed:.2f}s")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inserir chunk {chunk_num}: {e}")
            raise
    
    # Verificar total inserido
    total_db = db.execute_query("SELECT COUNT(*) as total FROM fact_producao")['total'].iloc[0]
    logger.info(f"‚úÖ Inser√ß√£o conclu√≠da! Total de registros inseridos: {total_db:,}")
    logger.info(f"üìä Esperado: {len(df):,}, Inserido: {total_db:,}")


def inserir_chunk_direto(chunk, db):
    """
    Insere um chunk de dados diretamente usando to_sql do pandas.
    
    Args:
        chunk: DataFrame com chunk de dados
        db: Gerenciador de banco de dados
    """
    chunk.to_sql(
        'fact_producao',
        db.engine,
        if_exists='append',
        index=False,
        method='multi',
        chunksize=100
    )
    
    logger.info("‚úÖ Chunk inserido com sucesso usando to_sql")


def main():
    """Fun√ß√£o principal que executa todo o processo ETL."""
    try:
        logger.info("üìö INICIANDO CRIA√á√ÉO DA FACT_PRODUCAO")
        logger.info("=" * 70)
        
        # 1. Conectar ao banco
        logger.info("1Ô∏è‚É£ Conectando ao banco de dados...")
        db = get_db_manager()
        
        # 2. Carregar dados de produ√ß√£o
        logger.info("2Ô∏è‚É£ Carregando dados de produ√ß√£o...")
        df_producao = carregar_dados_producao()
        
        # 3. Carregar mapeamentos das dimens√µes
        logger.info("3Ô∏è‚É£ Carregando mapeamentos das dimens√µes...")
        mapeamentos = carregar_dimensoes(db)
        
        # 4. Transformar dados
        logger.info("4Ô∏è‚É£ Transformando dados...")
        df_fato = transformar_dados_producao(df_producao, mapeamentos)
        
        # 5. Criar tabela
        logger.info("5Ô∏è‚É£ Criando tabela no banco...")
        criar_tabela(db)
        
        # 6. Inserir dados
        logger.info("6Ô∏è‚É£ Inserindo dados...")
        inserir_dados_producao(df_fato, db)
        
        logger.info("üéâ FACT_PRODUCAO CRIADA COM SUCESSO!")
        
    except Exception as e:
        logger.error(f"üí• Erro no processo: {e}")
        raise


if __name__ == "__main__":
    main()
